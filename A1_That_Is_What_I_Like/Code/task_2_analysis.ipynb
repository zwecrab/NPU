{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util_funs import Skipgram, SkipgramNeg, Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gensim\n",
    "# !pip install nltk\n",
    "# !pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skipgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Args\n",
    "\n",
    "skipgram_data = pickle.load(open(r'model/skipgram_metadata.pkl', 'rb'))\n",
    "\n",
    "cleaned_corpus = skipgram_data['corpus']\n",
    "vocabs = skipgram_data['vocab']\n",
    "word2index = skipgram_data['word2index']\n",
    "voc_size = skipgram_data['voc_size']\n",
    "emb_size = skipgram_data['embedding_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ws-\\AppData\\Local\\Temp\\ipykernel_34608\\1908435358.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  skipgram.load_state_dict(torch.load('model/word2vec_skipgram.pt'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Skipgram(\n",
       "  (embedding_center): Embedding(6966, 2)\n",
       "  (embedding_outside): Embedding(6966, 2)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the model and load saved parameters\n",
    "skipgram = Skipgram(voc_size, emb_size)\n",
    "skipgram.load_state_dict(torch.load('model/word2vec_skipgram.pt'))\n",
    "skipgram.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Args\n",
    "\n",
    "neg_skipgram_data = pickle.load(open(r'model/neg_sampling_metadata.pkl', 'rb'))\n",
    "\n",
    "cleaned_corpus = neg_skipgram_data['corpus']\n",
    "vocabs = neg_skipgram_data['vocab']\n",
    "word2index = neg_skipgram_data['word2index']\n",
    "voc_size = neg_skipgram_data['voc_size']\n",
    "emb_size = neg_skipgram_data['embedding_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ws-\\AppData\\Local\\Temp\\ipykernel_34608\\686751226.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  skipgramNeg.load_state_dict(torch.load('model/word2vec_neg_sampling.pt'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SkipgramNeg(\n",
       "  (embedding_center): Embedding(6966, 2)\n",
       "  (embedding_outside): Embedding(6966, 2)\n",
       "  (logsigmoid): LogSigmoid()\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the model and load saved parameters\n",
    "skipgramNeg = SkipgramNeg(voc_size, emb_size)\n",
    "skipgramNeg.load_state_dict(torch.load('model/word2vec_neg_sampling.pt'))\n",
    "skipgramNeg.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Args\n",
    "\n",
    "glove_data = pickle.load(open(r'model/glove_scratch_metadata.pkl', 'rb'))\n",
    "\n",
    "cleaned_corpus = neg_skipgram_data['corpus']\n",
    "vocabs = neg_skipgram_data['vocab']\n",
    "word2index = neg_skipgram_data['word2index']\n",
    "voc_size = neg_skipgram_data['voc_size']\n",
    "emb_size = neg_skipgram_data['embedding_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ws-\\AppData\\Local\\Temp\\ipykernel_34608\\2717802717.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  glove.load_state_dict(torch.load('model/glove_scratch.pt'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Glove(\n",
       "  (center_embedding): Embedding(6966, 2)\n",
       "  (outside_embedding): Embedding(6966, 2)\n",
       "  (center_bias): Embedding(6966, 1)\n",
       "  (outside_bias): Embedding(6966, 1)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the model and load saved parameters\n",
    "glove = Glove(voc_size, emb_size)\n",
    "glove.load_state_dict(torch.load('model/glove_scratch.pt'))\n",
    "glove.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you have to put this file in some python/gensim directory; just run it and it will inform where to put....\n",
    "glove_file = datapath('glove.6B.100d.txt')  #search on the google\n",
    "gensim = KeyedVectors.load_word2vec_format(glove_file, binary=False, no_header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity Accuracy Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"test_text/wordsim_similarity_goldstandard.txt\"\n",
    "\n",
    "content = open(file_path, 'r').readlines()\n",
    "\n",
    "sim_data = []\n",
    "\n",
    "for sent in content:\n",
    "    sim_data.append(sent.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tiger\\tcat\\t7.35',\n",
       " 'tiger\\ttiger\\t10.00',\n",
       " 'plane\\tcar\\t5.77',\n",
       " 'train\\tcar\\t6.31',\n",
       " 'television\\tradio\\t6.77']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"test_text/wordsim_similarity_goldstandard.txt\"\n",
    "\n",
    "content = open(file_path, 'r').readlines()\n",
    "\n",
    "sim_data = []\n",
    "\n",
    "for sent in content:\n",
    "    sim_data.append(sent.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_vectors(vocab, model):\n",
    "    \"\"\"Compute and stack vectors for all words in the vocabulary.\"\"\"\n",
    "    return torch.stack([model.get_embed(word) for word in vocab])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def sim_analysis(lines, model):\n",
    "    # Perform similarity analysis on word analogies.\n",
    "    # Compute all word vectors once\n",
    "    all_word_vectors = compute_vectors(vocabs, model)\n",
    "\n",
    "    correct = 0\n",
    "    skipped = 0\n",
    "\n",
    "    for line in lines:\n",
    "        words = line.split()\n",
    "\n",
    "        # Ensure the line has exactly four words\n",
    "        if len(words) != 4:\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        # Skip lines with unknown words\n",
    "        if any(word not in vocabs for word in words):\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        # Retrieve vectors for analogy words\n",
    "        try:\n",
    "            vectors = [model.get_embed(word.lower()) for word in words]\n",
    "            vectors = [vec if isinstance(vec, torch.Tensor) else torch.tensor(vec) for vec in vectors]\n",
    "        except KeyError:\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        # Perform vector manipulation\n",
    "        result_vector = vectors[1] - vectors[0] + vectors[2]\n",
    "        result_vector = result_vector.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "        # Calculate cosine similarities\n",
    "        similarities = F.cosine_similarity(result_vector, all_word_vectors)\n",
    "\n",
    "        # Get the closest word\n",
    "        closest_word_index = torch.argmax(similarities).item()\n",
    "        closest_word = vocabs[closest_word_index]\n",
    "\n",
    "        # Check if the predicted word matches the target\n",
    "        if closest_word == words[3]:\n",
    "            correct += 1\n",
    "\n",
    "    # Calculate accuracy\n",
    "    total = len(lines) - skipped\n",
    "    accuracy = (correct / total) * 100 if total > 0 else 0\n",
    "\n",
    "    print(f'Accuracy: {accuracy:.2f}%')\n",
    "    print(f'Skipped: {skipped} invalid words')\n",
    "    print(f'------------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_glove(lines, model):\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    skipped = 0  # Counter for skipped lines\n",
    "\n",
    "    for line in lines:\n",
    "        words = line.lower().strip().split()\n",
    "\n",
    "        # Skip invalid or OOV lines\n",
    "        if len(words) != 4:\n",
    "            skipped += 1\n",
    "            continue\n",
    "        if any(word not in model for word in words):\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        # Perform analogy\n",
    "        try:\n",
    "            result = model.most_similar(positive=[words[2], words[1]], negative=[words[0]], topn=1)\n",
    "            predicted_word = result[0][0]\n",
    "            total += 1\n",
    "\n",
    "            if predicted_word == words[3]:\n",
    "                correct += 1\n",
    "        except Exception as e:\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = (correct / total) * 100 if total > 0 else 0\n",
    "\n",
    "    # # Print results\n",
    "    print(f'Accuracy: {accuracy:.2f}%')\n",
    "    print(f'Skipped: {skipped} invalid words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Semantic and Syntatic Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the text file and create a list of tuples\n",
    "with open('test_text/word-test.v1.txt', 'r') as file:\n",
    "    sem_data = file.readlines()\n",
    "    \n",
    "with open('test_text/past_tense_syntatic.txt', 'r') as file:\n",
    "    syn_data = file.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work2Vec(Skipgram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models and their names\n",
    "models = {\n",
    "    'Word2Vec (Skipgram)': skipgram,\n",
    "    'Word2Vec (Neg Sampling)': skipgramNeg,\n",
    "    'GloVe from Scratch': glove,\n",
    "    'GloVe (Gensim)': gensim\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Similarity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Analysis:\n",
      "\n",
      "Word2Vec (Skipgram) on semantic similarity:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00%\n",
      "Skipped: 18427 invalid words\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "Word2Vec (Neg Sampling) on semantic similarity:\n",
      "Accuracy: 0.00%\n",
      "Skipped: 18427 invalid words\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "GloVe from Scratch on semantic similarity:\n",
      "Accuracy: 0.00%\n",
      "Skipped: 18427 invalid words\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "GloVe (Gensim) on semantic similarity:\n",
      "Accuracy: 63.11%\n",
      "Skipped: 13 invalid words\n"
     ]
    }
   ],
   "source": [
    "print(\"Semantic Analysis:\")\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n{model_name} on semantic similarity:\")\n",
    "    if model_name == 'GloVe (Gensim)':\n",
    "        # Use evaluate_glove for gensim model\n",
    "        evaluate_glove(sem_data, model)\n",
    "    else:\n",
    "        # Use similarities for other models\n",
    "        sim_analysis(sem_data, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syntatic Similarrity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syntatic Analysis:\n",
      "\n",
      "Word2Vec (Skipgram) on syntatic similarity:\n",
      "Accuracy: 0.00%\n",
      "Skipped: 1288 invalid words\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "Word2Vec (Neg Sampling) on syntatic similarity:\n",
      "Accuracy: 0.00%\n",
      "Skipped: 1288 invalid words\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "GloVe from Scratch on syntatic similarity:\n",
      "Accuracy: 0.00%\n",
      "Skipped: 1288 invalid words\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "GloVe (Gensim) on syntatic similarity:\n",
      "Accuracy: 55.45%\n",
      "Skipped: 0 invalid words\n"
     ]
    }
   ],
   "source": [
    "print(\"Syntatic Analysis:\")\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n{model_name} on syntatic similarity:\")\n",
    "    if model_name == 'GloVe (Gensim)':\n",
    "        # Use evaluate_glove for gensim model\n",
    "        evaluate_glove(syn_data, model)\n",
    "    else:\n",
    "        # Use similarities for other models\n",
    "        sim_analysis(syn_data, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Similarity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(A, B):\n",
    "\n",
    "    dot_product = np.dot(A.flatten(), B.flatten())\n",
    "    norm_a = np.linalg.norm(A)\n",
    "    norm_b = np.linalg.norm(B)\n",
    "\n",
    "    similarity = dot_product / (norm_a * norm_b)\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar(lines, model):\n",
    "    scores_real = []  # To store actual similarity scores (from the dataset)\n",
    "    scores_pred = []  # To store predicted similarity scores (using cosine similarity)\n",
    "\n",
    "    for line in lines:\n",
    "        words = line.split()  # Split line into words\n",
    "        vec = []  # List to store word vectors\n",
    "\n",
    "        # Assuming the first two words need to be compared\n",
    "        for word in words[:2]: \n",
    "            try:\n",
    "                # Attempt to get the vector for the word\n",
    "                vec.append(model.get_embed(word).detach().numpy())\n",
    "            except:\n",
    "                # If the word is not in the vocabulary, use the <UNK> token\n",
    "                vec.append(model.get_embed('<UNK>').detach().numpy())\n",
    "\n",
    "        # Store the actual similarity score from the dataset (third word)\n",
    "        scores_real.append(float(words[2]))  \n",
    "        \n",
    "        # Calculate the cosine similarity between the two words and store the predicted score\n",
    "        scores_pred.append(cosine_similarity(np.array(vec[0]), np.array(vec[1])))\n",
    "\n",
    "    # Calculate and return Spearman's rank correlation between actual and predicted scores\n",
    "    return spearmanr(scores_real, scores_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Function for Gensim\n",
    "\n",
    "def similar_gensim(lines, model):\n",
    "    scores_real = []\n",
    "    scores_pred = [] \n",
    "\n",
    "    for line in lines:\n",
    "        words = line.split()\n",
    "        vec = []\n",
    "        \n",
    "        for word in words[:2]:\n",
    "            try:\n",
    "                vec.append(model[word])\n",
    "            except KeyError:\n",
    "                vec.append(model['UNK'])\n",
    "        \n",
    "        # Store the actual similarity score from the dataset (third word)\n",
    "        scores_real.append(float(words[2]))\n",
    "\n",
    "        similarity_score = cosine_similarity(np.array(vec[0]), np.array(vec[1]))\n",
    "        scores_pred.append(similarity_score)\n",
    "\n",
    "    correlation, p_value = spearmanr(scores_real, scores_pred)\n",
    "    \n",
    "    return correlation, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models and their evaluation functions\n",
    "models = {\n",
    "    'Word2Vec (Skipgram)': (skipgram, similar),\n",
    "    'Word2Vec (Neg Sampling)': (skipgramNeg, similar),\n",
    "    'GloVe from Scratch': (glove, similar),\n",
    "    'GloVe (Gensim)': (gensim, similar_gensim)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Analysis:\n",
      "\n",
      "Word2Vec (Skipgram) correlation score: 0.2254\n",
      "\n",
      "Word2Vec (Neg Sampling) correlation score: 0.2899\n",
      "\n",
      "GloVe from Scratch correlation score: 0.1609\n",
      "\n",
      "GloVe (Gensim) correlation score: 0.6038\n"
     ]
    }
   ],
   "source": [
    "# Evaluate each model\n",
    "print(\"Similarity Analysis:\")\n",
    "for model_name, (model, eval_func) in models.items():\n",
    "    if model_name == 'gensim':\n",
    "        correlation_score = eval_func(sim_data, model)[0]\n",
    "    else:\n",
    "        correlation_score = eval_func(sim_data, model)[0]\n",
    "    \n",
    "    print(f'\\n{model_name} correlation score: {correlation_score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"test_text/wordsim_similarity_goldstandard_w_human.txt\"\n",
    "\n",
    "content = open(file_path, 'r').readlines()\n",
    "\n",
    "h_sim_data = []\n",
    "\n",
    "for sent in content:\n",
    "    h_sim_data.append(sent.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation between real scores and human scores: 0.9677\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "def similar_human(lines):\n",
    "    scores_real = []\n",
    "    scores_pred = []\n",
    "\n",
    "    for line in lines:\n",
    "        words = line.split()\n",
    "        scores_real.append(float(words[2]))  # Real score from the dataset (3rd column)\n",
    "        scores_pred.append(float(words[3]))  # Human score from the dataset (4th column)\n",
    "\n",
    "    # Calculate Spearman correlation\n",
    "    correlation, _ = spearmanr(scores_real, scores_pred)\n",
    "    return correlation\n",
    "\n",
    "# Calculate Spearman correlation\n",
    "correlation = similar_human(h_sim_data)\n",
    "print(f\"Spearman correlation between real scores and human scores: {correlation:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
